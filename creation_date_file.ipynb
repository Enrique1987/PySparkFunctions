{"cells":[{"cell_type":"code","source":["%scala\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\n\nval conf = spark.sparkContext.hadoopConfiguration\nval fs = FileSystem.get(conf)\nval dirPath = new Path(\"dbfs:/mnt/dlk/youpath\")\nval filestatus = fs.listStatus(dirPath )\nfilestatus.foreach(f => println(f.getModificationTime))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4b805521-f8e3-4420-bf05-a03bf04cc752"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\n\nimport java.time.{Instant, ZoneId, ZonedDateTime} \n\nval timeInMillis = System.currentTimeMillis()\n//timeInMillis: Long = 1486988060666\n\nval instant = Instant.ofEpochMilli(timeInMillis)\n// print(instant)\n\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\n\nval conf = spark.sparkContext.hadoopConfiguration\nval fs = FileSystem.get(conf)\nval dirPath = new Path(\"your_path\")\nval filestatus = fs.listStatus(dirPath )\n// filestatus.foreach(f => println(f.getModificationTime))\n// filestatus.foreach(f => println(f.getPath))\nfilestatus.foreach(f => {\n                        println(\"file time creation...: \" + Instant.ofEpochMilli(f.getModificationTime)) \n                        println(\"file path .... \" + f.getPath)\n                        })\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e93bd508-d8a4-4082-bc0a-b1555ad8900e"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"creation_date_file","dashboards":[],"language":"python","widgets":{},"notebookOrigID":162669049861299}},"nbformat":4,"nbformat_minor":0}
